import pandas as pd 
import numpy as np 
from sklearn.preprocessing import LabelEncoder

def prediction(P,Q):
    return np.dot(P.T,Q)

def rmse(I,R,Q,P):
    return np.sqrt(np.sum((I * (R - prediction(P,Q)))**2)/len(R[R > 0]))


def stochasticGradientSolution():
	df = pd.read_csv("./train.csv")
	n_users = df["userId"].unique().shape[0]
	n_items = df["itemId"].unique().shape[0]
	user_encoder = LabelEncoder()
	item_encoder = LabelEncoder()
	df["userId"] = user_encoder.fit_transform(df["userId"])
	df["itemId"] = item_encoder.fit_transform(df["itemId"])
	R = np.zeros((n_users,n_items))
	for line in df.itertuples():
		R[line[2],line[3]] = line[4]
	I = R.copy()
	I[I>0] = 1
	I[I==0] = 0

	lmbda = 0.1 # Regularisation weight
	k = 5  # Dimensionality of the latent feature space
	m, n = R.shape  # Number of users and items
	n_epochs = 10  # Number of epochs
	gamma=0.01  # Learning rate

	P = 3 * np.random.rand(k,m) # Latent user feature matrix
	Q = 3 * np.random.rand(k,n) #

	train_errors = []

	#Only consider non-zero matrix 
	users,items = R.nonzero()      
	for epoch in xrange(n_epochs):
		for u, i in zip(users,items):
			e = R[u, i] - prediction(P[:,u],Q[:,i])  # Calculate error for gradient
			P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # Update latent user feature matrix
			Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # Update latent movie feature matrix
		train_rmse = rmse(I,R,Q,P) # Calculate root mean squared error from train dataset
		train_errors.append(train_rmse)

	R = pd.DataFrame(R)
	R_hat=pd.DataFrame(prediction(P,Q))

	print "train_errors",  train_errors

	print "fffffffff"

	R.to_csv("R.csv",index=False)
	R_hat.to_csv("R_hat.csv",index=False)

	# ratings = pd.DataFrame(data=R.loc[16,R.loc[16,:] > 0]).head(n=5)
	# ratings['Prediction'] = R_hat.loc[16,R.loc[16,:] > 0]
	# ratings.columns = ['Actual Rating', 'Predicted Rating']


if __name__ == '__main__':
	stochasticGradientSolution()